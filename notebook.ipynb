{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from model import DSN\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract frames at a specified frame rate and append paths to a list\n",
    "def extract_frames(video_path, output_folder, frame_rate=2):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file.\")\n",
    "        return\n",
    "\n",
    "    frame_width = int(cap.get(3))  # Get the width of the frames\n",
    "    frame_height = int(cap.get(4))  # Get the height of the frames\n",
    "\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can change the codec as needed\n",
    "    output_path = os.path.join(output_folder, \"output_video.mp4\")\n",
    "    out = cv2.VideoWriter(output_path, fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    frames = []  # List to store frame paths\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time >= 1.0 / frame_rate:\n",
    "            out.write(frame)\n",
    "            frame_count += 1\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Save the frame as an image file\n",
    "            frame_filename = f\"frame_{frame_count:04d}.png\"\n",
    "            frame_path = os.path.join(output_folder, frame_filename)\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            frames.append(frame_path)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Frames extracted: {frame_count}\")\n",
    "    print(f\"Frames per second: {frame_rate}\")\n",
    "    print(f\"Output video saved to: {output_path}\")\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames extracted: 121\n",
      "Frames per second: 2\n",
      "Output video saved to: ./frames\\output_video.mp4\n",
      "Extracted frame paths: ['./frames\\\\frame_0001.png', './frames\\\\frame_0002.png', './frames\\\\frame_0003.png', './frames\\\\frame_0004.png', './frames\\\\frame_0005.png', './frames\\\\frame_0006.png', './frames\\\\frame_0007.png', './frames\\\\frame_0008.png', './frames\\\\frame_0009.png', './frames\\\\frame_0010.png', './frames\\\\frame_0011.png', './frames\\\\frame_0012.png', './frames\\\\frame_0013.png', './frames\\\\frame_0014.png', './frames\\\\frame_0015.png', './frames\\\\frame_0016.png', './frames\\\\frame_0017.png', './frames\\\\frame_0018.png', './frames\\\\frame_0019.png', './frames\\\\frame_0020.png', './frames\\\\frame_0021.png', './frames\\\\frame_0022.png', './frames\\\\frame_0023.png', './frames\\\\frame_0024.png', './frames\\\\frame_0025.png', './frames\\\\frame_0026.png', './frames\\\\frame_0027.png', './frames\\\\frame_0028.png', './frames\\\\frame_0029.png', './frames\\\\frame_0030.png', './frames\\\\frame_0031.png', './frames\\\\frame_0032.png', './frames\\\\frame_0033.png', './frames\\\\frame_0034.png', './frames\\\\frame_0035.png', './frames\\\\frame_0036.png', './frames\\\\frame_0037.png', './frames\\\\frame_0038.png', './frames\\\\frame_0039.png', './frames\\\\frame_0040.png', './frames\\\\frame_0041.png', './frames\\\\frame_0042.png', './frames\\\\frame_0043.png', './frames\\\\frame_0044.png', './frames\\\\frame_0045.png', './frames\\\\frame_0046.png', './frames\\\\frame_0047.png', './frames\\\\frame_0048.png', './frames\\\\frame_0049.png', './frames\\\\frame_0050.png', './frames\\\\frame_0051.png', './frames\\\\frame_0052.png', './frames\\\\frame_0053.png', './frames\\\\frame_0054.png', './frames\\\\frame_0055.png', './frames\\\\frame_0056.png', './frames\\\\frame_0057.png', './frames\\\\frame_0058.png', './frames\\\\frame_0059.png', './frames\\\\frame_0060.png', './frames\\\\frame_0061.png', './frames\\\\frame_0062.png', './frames\\\\frame_0063.png', './frames\\\\frame_0064.png', './frames\\\\frame_0065.png', './frames\\\\frame_0066.png', './frames\\\\frame_0067.png', './frames\\\\frame_0068.png', './frames\\\\frame_0069.png', './frames\\\\frame_0070.png', './frames\\\\frame_0071.png', './frames\\\\frame_0072.png', './frames\\\\frame_0073.png', './frames\\\\frame_0074.png', './frames\\\\frame_0075.png', './frames\\\\frame_0076.png', './frames\\\\frame_0077.png', './frames\\\\frame_0078.png', './frames\\\\frame_0079.png', './frames\\\\frame_0080.png', './frames\\\\frame_0081.png', './frames\\\\frame_0082.png', './frames\\\\frame_0083.png', './frames\\\\frame_0084.png', './frames\\\\frame_0085.png', './frames\\\\frame_0086.png', './frames\\\\frame_0087.png', './frames\\\\frame_0088.png', './frames\\\\frame_0089.png', './frames\\\\frame_0090.png', './frames\\\\frame_0091.png', './frames\\\\frame_0092.png', './frames\\\\frame_0093.png', './frames\\\\frame_0094.png', './frames\\\\frame_0095.png', './frames\\\\frame_0096.png', './frames\\\\frame_0097.png', './frames\\\\frame_0098.png', './frames\\\\frame_0099.png', './frames\\\\frame_0100.png', './frames\\\\frame_0101.png', './frames\\\\frame_0102.png', './frames\\\\frame_0103.png', './frames\\\\frame_0104.png', './frames\\\\frame_0105.png', './frames\\\\frame_0106.png', './frames\\\\frame_0107.png', './frames\\\\frame_0108.png', './frames\\\\frame_0109.png', './frames\\\\frame_0110.png', './frames\\\\frame_0111.png', './frames\\\\frame_0112.png', './frames\\\\frame_0113.png', './frames\\\\frame_0114.png', './frames\\\\frame_0115.png', './frames\\\\frame_0116.png', './frames\\\\frame_0117.png', './frames\\\\frame_0118.png', './frames\\\\frame_0119.png', './frames\\\\frame_0120.png', './frames\\\\frame_0121.png']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "video_path = \"./video/IronMan.mp4\"\n",
    "output_folder = \"./frames\"\n",
    "frames = extract_frames(video_path, output_folder, frame_rate=2)\n",
    "\n",
    "# Now 'extracted_frame_paths' contains a list of file paths for the extracted frames\n",
    "print(\"Extracted frame paths:\", frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "def _get_features(frames, gpu=True, batch_size=1):\n",
    "    # Load pre-trained GoogLeNet model\n",
    "    googlenet = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', weights='GoogLeNet_Weights.DEFAULT')\n",
    "\n",
    "    # Remove the classification layer (last layer) to obtain features\n",
    "    googlenet = torch.nn.Sequential(*(list(googlenet.children())[:-1]))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    googlenet.eval()\n",
    "\n",
    "    # Initialize a list to store the features\n",
    "    features = []\n",
    "\n",
    "    # Image preprocessing pipeline\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Iterate through frames\n",
    "    for frame_path in frames:\n",
    "        # Load and preprocess the frame\n",
    "        input_image = Image.open(frame_path)\n",
    "        input_tensor = preprocess(input_image)\n",
    "        input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Move the input and model to GPU if available\n",
    "        if gpu:\n",
    "            input_batch = input_batch.to('cuda')\n",
    "            googlenet.to('cuda')\n",
    "\n",
    "        # Perform feature extraction\n",
    "        with torch.no_grad():\n",
    "            output = googlenet(input_batch)\n",
    "\n",
    "        # Append the features to the list\n",
    "        features.append(output.squeeze().cpu().numpy())\n",
    "\n",
    "    # Convert the list of features to a NumPy array\n",
    "    features = np.array(features)\n",
    "\n",
    "    return features.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "def _get_probs(features, gpu=True, mode=0):\n",
    "    model_cache_key = \"keyframes_rl_model_cache_\" + str(mode)\n",
    "\n",
    "    if mode == 1:\n",
    "        model_path = \"pretrained_model/model_1.pth.tar\"\n",
    "    else:\n",
    "        model_path = \"pretrained_model/model_0.pth.tar\"\n",
    "    model = DSN(in_dim=1024, hid_dim=256, num_layers=1, cell=\"lstm\")\n",
    "    if gpu:\n",
    "        checkpoint = torch.load(model_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    if gpu:\n",
    "        model = nn.DataParallel(model).cuda()\n",
    "    model.eval()\n",
    "\n",
    "    seq = torch.from_numpy(features).unsqueeze(0)\n",
    "    if gpu: seq = seq.cuda()\n",
    "    probs = model(seq)\n",
    "    probs = probs.data.cpu().squeeze().numpy()\n",
    "    return probs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Reuben/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00076084 0.02302736 0.01229232 ... 0.         0.28099012 0.22683515]\n",
      " [0.00292103 0.03626517 0.07445761 ... 0.02032194 0.2840359  0.4727426 ]\n",
      " [0.01197546 0.03877074 0.0361792  ... 0.02937937 0.1893131  0.01219838]\n",
      " ...\n",
      " [0.29286134 0.1444928  0.6816671  ... 0.21294546 0.45816123 0.10849144]\n",
      " [0.20330043 0.24632838 0.7150742  ... 0.10341235 0.38244024 0.08002178]\n",
      " [0.42814285 0.05499694 0.34291217 ... 0.09384909 0.2126687  0.01221014]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Reuben/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92428774 0.9405393  0.9403023  0.947059   0.95628273 0.9597538\n",
      " 0.9563509  0.9603559  0.96274513 0.95856637 0.95754725 0.95754963\n",
      " 0.9563159  0.9566882  0.9583453  0.9625568  0.9575483  0.95946056\n",
      " 0.9624249  0.96213436 0.9647548  0.9651764  0.96348166 0.95760465\n",
      " 0.9573023  0.9483761  0.9586274  0.96309924 0.9626103  0.9611359\n",
      " 0.9619318  0.96068597 0.9581939  0.9624936  0.96567476 0.9605381\n",
      " 0.96248174 0.9563921  0.95681167 0.95889807 0.96175766 0.960153\n",
      " 0.96098644 0.9651984  0.9620243  0.96110964 0.96562564 0.9664658\n",
      " 0.96179694 0.96532124 0.96164066 0.95916677 0.95536464 0.95793706\n",
      " 0.9554321  0.957518   0.9589432  0.9617849  0.9616793  0.96390814\n",
      " 0.96845955 0.96928865 0.96415085 0.9699055  0.9697425  0.9693654\n",
      " 0.968953   0.9685338  0.97116166 0.9659987  0.9653397  0.9650486\n",
      " 0.9665922  0.96858764 0.9641196  0.9665096  0.9669485  0.9676694\n",
      " 0.9621605  0.9650141  0.9621402  0.9645135  0.96676564 0.9643471\n",
      " 0.961055   0.9524622  0.950604   0.95916736 0.9645953  0.96048313\n",
      " 0.95135003 0.96012664 0.9619521  0.9622835  0.9601441  0.9600232\n",
      " 0.9565954  0.96530616 0.97218895 0.96962714 0.9698157  0.9699823\n",
      " 0.9713922  0.9684715  0.9652533  0.9663489  0.9684427  0.96916044\n",
      " 0.9690806  0.96967846 0.9692486  0.9679079  0.9656187  0.9651025\n",
      " 0.9592233  0.96150166 0.9640511  0.9623646  0.95711124 0.9445146\n",
      " 0.90847075]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Reuben/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 1024)\n",
      "(1024,)\n",
      "(121,)\n"
     ]
    }
   ],
   "source": [
    "print(_get_features(frames))\n",
    "print(_get_probs(_get_features(frames)))\n",
    "\n",
    "features = _get_features(frames)\n",
    "print(features.shape)\n",
    "print(features[0].shape)\n",
    "print(_get_probs(features).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 🌴 Change the values in this section\n",
    "\n",
    "# @markdown Select the source of the audio/video file to be transcribed\n",
    "input_format = \"local\" #@param [\"youtube\", \"gdrive\", \"local\"]\n",
    "\n",
    "# @markdown Enter the URL of the YouTube video or the path of the audio file to be transcribed\n",
    "file =video_path #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Click here if you'd like to save the transcription as text file\n",
    "plain = True #@param {type:\"boolean\"}\n",
    "\n",
    "# @markdown Click here if you'd like to save the transcription as an SRT file\n",
    "srt = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Click here if you'd like to save the transcription as a VTT file\n",
    "vtt = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Click here if you'd like to save the transcription as a TSV file\n",
    "tsv = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Click here if you'd like to download the transcribed file(s) locally\n",
    "download = True #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "import whisper\n",
    "from whisper.utils import get_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [03:30<00:00, 7.26MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# Use CUDA, if available\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the desired model\n",
    "model = whisper.load_model(\"medium.en\").to(DEVICE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_snake_case(name):\n",
    "    return name.lower().replace(\" \", \"_\").replace(\":\", \"_\").replace(\"__\", \"_\")\n",
    "\n",
    "def download_youtube_audio(url,  file_name = None, out_dir = \".\"):\n",
    "    \"Download the audio from a YouTube video\"\n",
    "    yt = YouTube(url)\n",
    "    if file_name is None:\n",
    "        file_name = Path(out_dir, to_snake_case(yt.title)).with_suffix(\".mp4\")\n",
    "    yt = (yt.streams\n",
    "            .filter(only_audio = True, file_extension = \"mp4\")\n",
    "            .order_by(\"abr\")\n",
    "            .desc())\n",
    "    return yt.first().download(filename = file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_file(model, file, plain, srt, vtt, tsv, download):\n",
    "    \"\"\"\n",
    "    Runs Whisper on an audio file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Whisper\n",
    "        The Whisper model instance.\n",
    "\n",
    "    file: str\n",
    "        The file path of the file to be transcribed.\n",
    "\n",
    "    plain: bool\n",
    "        Whether to save the transcription as a text file or not.\n",
    "\n",
    "    srt: bool\n",
    "        Whether to save the transcription as an SRT file or not.\n",
    "\n",
    "    vtt: bool\n",
    "        Whether to save the transcription as a VTT file or not.\n",
    "\n",
    "    tsv: bool\n",
    "        Whether to save the transcription as a TSV file or not.\n",
    "\n",
    "    download: bool\n",
    "        Whether to download the transcribed file(s) or not.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary containing the resulting text (\"text\") and segment-level details (\"segments\"), and\n",
    "    the spoken language (\"language\"), which is detected when `decode_options[\"language\"]` is None.\n",
    "    \"\"\"\n",
    "    file_path = Path(file)\n",
    "    print(f\"Transcribing file: {file_path}\\n\")\n",
    "\n",
    "    output_directory = file_path.parent\n",
    "\n",
    "    # Run Whisper\n",
    "    result = model.transcribe(file, verbose = False, language = \"en\")\n",
    "\n",
    "    if plain:\n",
    "        txt_path = file_path.with_suffix(\".txt\")\n",
    "        print(f\"\\nCreating text file\")\n",
    "\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as txt:\n",
    "            txt.write(result[\"text\"])\n",
    "    if srt:\n",
    "        print(f\"\\nCreating SRT file\")\n",
    "        srt_writer = get_writer(\"srt\", output_directory)\n",
    "        srt_writer(result, str(file_path.stem))\n",
    "\n",
    "    if vtt:\n",
    "        print(f\"\\nCreating VTT file\")\n",
    "        vtt_writer = get_writer(\"vtt\", output_directory)\n",
    "        vtt_writer(result, str(file_path.stem))\n",
    "\n",
    "    if tsv:\n",
    "        print(f\"\\nCreating TSV file\")\n",
    "\n",
    "        tsv_writer = get_writer(\"tsv\", output_directory)\n",
    "        tsv_writer(result, str(file_path.stem))\n",
    "\n",
    "    if download:\n",
    "        from google.colab import files\n",
    "\n",
    "        colab_files = Path(\"/content\")\n",
    "        stem = file_path.stem\n",
    "\n",
    "        for colab_file in colab_files.glob(f\"{stem}*\"):\n",
    "            if colab_file.suffix in [\".txt\", \".srt\", \".vtt\", \".tsv\"]:\n",
    "                print(f\"Downloading {colab_file}\")\n",
    "                files.download(str(colab_file))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing file: video\\IronMan.mp4\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     result \u001b[38;5;241m=\u001b[39m transcribe_file(model, file, plain, srt, vtt, tsv, download)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Run Whisper on the specified file\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvtt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtsv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 39\u001b[0m, in \u001b[0;36mtranscribe_file\u001b[1;34m(model, file, plain, srt, vtt, tsv, download)\u001b[0m\n\u001b[0;32m     36\u001b[0m output_directory \u001b[38;5;241m=\u001b[39m file_path\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Run Whisper\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plain:\n\u001b[0;32m     42\u001b[0m     txt_path \u001b[38;5;241m=\u001b[39m file_path\u001b[38;5;241m.\u001b[39mwith_suffix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Studies\\Engineering\\Semester 7\\Project Phase 1\\Cinecomic\\venv\\Lib\\site-packages\\whisper\\transcribe.py:122\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[0;32m    119\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m mel \u001b[38;5;241m=\u001b[39m \u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m content_frames \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m N_FRAMES\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Studies\\Engineering\\Semester 7\\Project Phase 1\\Cinecomic\\venv\\Lib\\site-packages\\whisper\\audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[1;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(audio):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 140\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(audio)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Studies\\Engineering\\Semester 7\\Project Phase 1\\Cinecomic\\venv\\Lib\\site-packages\\whisper\\audio.py:58\u001b[0m, in \u001b[0;36mload_audio\u001b[1;34m(file, sr)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Reuben\\Python\\Lib\\subprocess.py:546\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    543\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m    544\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 546\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mD:\\Reuben\\Python\\Lib\\subprocess.py:1022\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1019\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1020\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1022\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mD:\\Reuben\\Python\\Lib\\subprocess.py:1491\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1491\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1493\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1504\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1507\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1508\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "if input_format == \"youtube\":\n",
    "    # Download the audio stream of the YouTube video\n",
    "    audio = download_youtube_audio(file)\n",
    "    print(f\"Downloading audio stream: {audio}\")\n",
    "\n",
    "    # Run Whisper on the audio stream\n",
    "    result = transcribe_file(model, audio, plain, srt, vtt, tsv, download)\n",
    "elif input_format == \"gdrive\":\n",
    "    # Authorize a connection between Google Drive and Google Colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Run Whisper on the specified file\n",
    "    result = transcribe_file(model, file, plain, srt, vtt, tsv, download)\n",
    "elif input_format == \"local\":\n",
    "    # Run Whisper on the specified file\n",
    "    result = transcribe_file(model, file, plain, srt, vtt, tsv, download)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
